{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation\\Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MvAMWl-LlFUf",
        "ekpJ05ZVlACG",
        "KbGcVbTd4UC2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvAMWl-LlFUf"
      },
      "source": [
        "# Loading Data .."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a_T5RY6YKHq"
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ksai9v8YUU9"
      },
      "source": [
        "pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMZNQ0QBcRLH"
      },
      "source": [
        "pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9y68iiUFmmu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVVrcGoE5kJ"
      },
      "source": [
        "cd '/content/drive/MyDrive/archive-3Original/COVID'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX4c2I-v7kAY"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USVv9g95JicH"
      },
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIr3FmHBKPy5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxjPytesIq1g",
        "outputId": "928e3757-64f0-4bf9-f1f7-a0ceb80943ba"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DatasetA/CP')\n",
        "import os, fnmatch\n",
        "def find(pattern, path):\n",
        "    \"\"\"Utility to find files wrt a regex search\"\"\"\n",
        "    result = []\n",
        "    for r, dirs, files in os.walk(path):\n",
        "        for name in files:\n",
        "            if fnmatch.fnmatch(name, pattern):\n",
        "                result.append(os.path.join(r, name))\n",
        "                #print(r, name)\n",
        "    return result\n",
        "FIND_FOLDER = '/content/drive/MyDrive/DatasetA/CP/-COVID-'\n",
        "png_files = find('*.*', FIND_FOLDER)\n",
        "print(len(png_files),\"Files Found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5238 Files Found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv04clxZIri5"
      },
      "source": [
        "import random\n",
        "num_subset = 5238\n",
        "#random.seed(42) # 42 # 2021\n",
        "subset_png_files =  random.choices(png_files, k=num_subset) # dcm_files[:3]\n",
        "subset_png_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hpy2qsrhrEx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekpJ05ZVlACG"
      },
      "source": [
        "# Define & Load UNET Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdoxqCxKlPcH"
      },
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctvmM5oylRpj"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8V-Nzgjjrdn"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = keras.flatten(y_true)\n",
        "    y_pred_f = keras.flatten(y_pred)\n",
        "    intersection = keras.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def unet(input_size=(256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA6l0WxnjyQe"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model = unet(input_size=(512,512,1))\n",
        "model.compile(opt, loss=dice_coef_loss,\n",
        "                  metrics=[dice_coef, 'binary_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVa8x048j4Gt"
      },
      "source": [
        "**Load the Pretrained UNet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0QX-FRKj3By"
      },
      "source": [
        "model_weights_path = \"/content/drive/MyDrive/cxr_reg_png_weights.best.hdf5\"\n",
        "\n",
        "model.load_weights(model_weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVd6xlsihIg1"
      },
      "source": [
        "viz_counter=0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw1zZpGmkBCg"
      },
      "source": [
        "\"\"\"\n",
        "Shapes that you wish to resize to\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "image_dataset = []\n",
        "Shape_X,Shape_Y=512,512\n",
        "\n",
        "for i in subset_png_files:\n",
        "    resized_image_data = cv2.resize(cv2.imread(os.path.join(FIND_FOLDER,i)),(Shape_Y,Shape_X))[:,:,0]\n",
        "    #clahe = cv2.createCLAHE(cliplimit=3.0, tileGridSize=(8,8))\n",
        "    #clahe_img = clahe.apply(resized_image_data)\n",
        "    #color_clahe = cv2.merge((clahe_img,a,b))\n",
        "    #CLAHE_img = cv2.cvtColor(color_clahe,cv2.COLOR_LAB2BGR)\n",
        "    image_dataset.append(np.array(resized_image_data))\n",
        "  \n",
        "    ##dicom_dict, modified_image_data = dicom_dataset_to_dict(path)\n",
        "    #resized_image_data = cv2.resize(modified_image_data,(Shape_Y,Shape_X)) # cv2 has this opposite\n",
        "    # props(resized_image_data)\n",
        "    prep_unet_input_img_1 = resized_image_data.reshape(1,Shape_X,Shape_Y,1)\n",
        "    prep_unet_input_img = (prep_unet_input_img_1-127.0)/127.0\n",
        "    pred_img = model.predict(prep_unet_input_img)\n",
        "    pred_img_preprocessed_1 = np.squeeze(pred_img)\n",
        "    pred_img_preprocessed = (pred_img_preprocessed_1*255>127).astype(np.int8)\n",
        "    # props(pred_img_preprocessed)\n",
        "    # print(\"Unique Values :\",np.unique(pred_img_preprocessed))\n",
        "    res = cv2.bitwise_and(resized_image_data,resized_image_data,mask = pred_img_preprocessed)\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 12))\n",
        "    ax[0].imshow(clahe_img, cmap=\"viridis\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(pred_img_preprocessed, cmap=\"viridis\")    \n",
        "    ax[1].axis('off')\n",
        "    ax[2].imshow(res, cmap=\"viridis\")    \n",
        "    ax[2].axis('off')\n",
        "    #plt.savefig(str(viz_counter)+\".png\",dpi=300)\n",
        "    viz_counter+=1\n",
        "    cv2.imwrite(str(viz_counter)+\".png\",res)\n",
        "    #viz_counter+=1\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-j3Z9Wko_X"
      },
      "source": [
        "df = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})\n",
        "df.to_csv('meta.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNryEbuAkr6n"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "#taken from : https://www.kaggle.com/xhlulu/recursion-2019-load-resize-and-save-images\n",
        "\n",
        "def zip_and_remove(path):\n",
        "    ziph = zipfile.ZipFile(f'{path}.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "    \n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            ziph.write(file_path)\n",
        "            os.remove(file_path)\n",
        "    \n",
        "    ziph.close()\n",
        "    shutil.rmtree(path)\n",
        "save_dir = '/content/drive/MyDrive/Segmented'\n",
        "zip_and_remove(save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbGcVbTd4UC2"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq0M_Uex61DL"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Construct an instance of the ImageDataGenerator class\n",
        "# Pass the augmentation parameters through the constructor. \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        shear_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')    #Also try nearest, constant, reflect, wrap\n",
        "\n",
        "dataset = []\n",
        "\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow_from_directory(directory='/content/drive/MyDrive/SegmentedDataset1/SegmentedUpdated/cap', \n",
        "                                         batch_size=1,  \n",
        "                                         target_size=(256, 256),\n",
        "                                         color_mode=\"rgb\",\n",
        "                                         save_to_dir='/content/drive/MyDrive/SegmentedDataset1/SegmentedUpdated/cap/CAP', \n",
        "                                         save_prefix='aug', \n",
        "                                         save_format='png'):\n",
        "    i += 1\n",
        "    if i > 2000:\n",
        "        break \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}